{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "820656f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6caf173c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Folder structure\n",
    "\n",
    "The following folder structure will be used in this project\n",
    "\n",
    "VoiceSimilarityAnalysis-code\n",
    "├── data\n",
    "│   ├── download              # Contains downloaded zip files (e.g. ABI-1_Corpus.zip)\n",
    "│   ├── raw/                   # Unzipped original dataset (14 accent folders)\n",
    "│   └── cleansed/              # Contains only the filtered \"shortpassage\" .wav files\n",
    "│\n",
    "├── reports/                  # Drafts and final version of the report\n",
    "│\n",
    "├── results/                  # Output files: embeddings, similarity scores, matrices, plots\n",
    "│\n",
    "├── appendix/                 # Generative AI chat logs for submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "769ac352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports go here\n",
    "import os\n",
    "import zipfile\n",
    "import gdown\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022a72ea",
   "metadata": {},
   "source": [
    "## Step 1 - download the dataset\n",
    "\n",
    "In an effort to totally automate the process, the dataset will be downloaded in a raw-data folder using the following code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7bbad0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=18FWBn4B6gQifOtf1C9JCQv4Lrs8C1uvu\n",
      "From (redirected): https://drive.google.com/uc?id=18FWBn4B6gQifOtf1C9JCQv4Lrs8C1uvu&confirm=t&uuid=d960d3e7-f87b-4e67-a75c-4db67582f7ff\n",
      "To: f:\\work\\masters-ai\\ari5121-project\\VoiceSimilarityAnalysis-code\\data\\download\\ABI-1_Corpus\\ABI-1_Corpus.zip\n",
      "100%|██████████| 2.82G/2.82G [04:04<00:00, 11.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data downloaded...\n"
     ]
    }
   ],
   "source": [
    "# 7 minutes on Costa wifi -- execute and have a coffee\n",
    "\n",
    "# gdrive id\n",
    "file_id = \"18FWBn4B6gQifOtf1C9JCQv4Lrs8C1uvu\"\n",
    "\n",
    "# download the file\n",
    "download_folder = os.path.join(\"data\", \"download\", \"ABI-1_Corpus\")\n",
    "if not os.path.exists(download_folder):\n",
    "    os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "download_path = os.path.join(download_folder, \"ABI-1_Corpus.zip\")\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", download_path, quiet=False)\n",
    "\n",
    "# open the zip\n",
    "raw_folder = os.path.join(\"data\", \"raw\", \"ABI-1_Corpus\")\n",
    "if not os.path.exists(raw_folder):\n",
    "    os.makedirs(raw_folder, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(raw_folder)\n",
    "\n",
    "print(\"Raw data downloaded...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7081537",
   "metadata": {},
   "source": [
    "## Step 2 - Cleanse the dataset\n",
    "\n",
    "We will only keep the \"shortpassage*.wav\" files for each accent in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3235d557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleansing completed...\n"
     ]
    }
   ],
   "source": [
    "raw_data_folder = \"data/raw/ABI-1_Corpus/ABI-1 Corpus/accents\"\n",
    "cleansed_dir = \"data/cleansed\"\n",
    "\n",
    "\n",
    "# list accent folders removing the annoying folders\n",
    "accents = [accent_folder for accent_folder in os.listdir(raw_data_folder) if not accent_folder.startswith(\".\")]\n",
    "# go through all accents\n",
    "for accent in accents:\n",
    "    accent_path = os.path.join(raw_data_folder, accent)\n",
    "    # list all genders in each accent\n",
    "    genders = [gender_folder for gender_folder in os.listdir(accent_path) if not gender_folder.startswith(\".\")]\n",
    "    # go through all genders in each accent\n",
    "    for gender in genders:  \n",
    "        gender_folder = os.path.join(accent_path, gender)\n",
    "        # go througgh each speaker in each gender\n",
    "        # lsit all speakers\n",
    "        speakers = [speaker for speaker in os.listdir(gender_folder) if not speaker.startswith(\".\")]\n",
    "        for speaker in speakers:\n",
    "            speaker_path = os.path.join(gender_folder, speaker)\n",
    "\n",
    "            # store resulting  data in cleaned/accent/gender/speaker\n",
    "            dest_path = os.path.join(cleansed_dir, accent, gender, speaker)\n",
    "            os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "            # copy only filenames that  are shortpassage*.wav\n",
    "            # go throough all files        \n",
    "            for filename in os.listdir(speaker_path):\n",
    "                if re.fullmatch(r\"shortpassage.*\\.wav\", filename):\n",
    "\n",
    "                    src_file = os.path.join(speaker_path, filename)\n",
    "                    dst_file = os.path.join(dest_path, filename)\n",
    "                    shutil.copy2(src_file, dst_file)\n",
    "\n",
    "print(\"Cleansing completed...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feedc743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\work\\masters-ai\\ari5121-project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing existing model folder: model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\work\\masters-ai\\ari5121-project\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in F:\\work\\masters-ai\\ari5121-project\\VoiceSimilarityAnalysis-code\\model\\models--microsoft--wavlm-base-plus-sv. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded...\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor, AutoModel\n",
    "\n",
    "\n",
    "# model folder at microsoft and corresponding local folder\n",
    "model_name = \"microsoft/wavlm-base-plus-sv\"\n",
    "local_dir = \"model\"\n",
    "\n",
    "# empty the model folder\n",
    "if os.path.exists(local_dir):\n",
    "    print(f\"Removing existing model folder: {local_dir}\")\n",
    "    shutil.rmtree(local_dir)\n",
    "\n",
    "\n",
    "\n",
    "# downlad the model\n",
    "processor = Wav2Vec2FeatureExtractor.from_pretrained(model_name, cache_dir=local_dir)\n",
    "model = AutoModel.from_pretrained(model_name, cache_dir=local_dir)\n",
    "\n",
    "print(f\"Model downloaded...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52a246af",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3571725436.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mJust testing the code on huggingface\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Just testing the code on huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0cdaa36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "---> ['soundfile']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\work\\masters-ai\\ari5121-project\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "tensor([[-1.7097e-02, -1.5231e-02, -1.8405e-02,  1.5202e-02, -9.5779e-03,\n",
      "          1.1019e-02,  1.7085e-03, -1.1638e-02, -3.3138e-02, -1.4006e-02,\n",
      "         -1.7701e-02, -2.1907e-02, -1.9460e-02, -2.0179e-02, -9.9428e-03,\n",
      "         -2.4083e-02, -1.6532e-02, -1.4741e-02, -1.8193e-02, -9.3101e-02,\n",
      "         -1.8302e-02, -2.0148e-02, -1.4272e-02, -1.7597e-02, -1.8309e-02,\n",
      "         -1.4506e-02, -1.6477e-02, -3.1048e-02, -1.4618e-02,  3.1411e-02,\n",
      "         -1.7857e-02, -1.4265e-02, -1.6262e-02, -2.8616e-02, -1.7755e-02,\n",
      "         -2.2684e-02,  3.0300e-02, -1.3263e-02, -7.4688e-03, -1.8852e-02,\n",
      "         -2.5600e-02, -2.3731e-02, -1.6097e-02, -2.1447e-02, -2.4125e-02,\n",
      "         -2.1679e-02, -1.9913e-02, -1.1094e-02, -2.7766e-02, -1.6725e-02,\n",
      "         -1.7442e-02, -2.0374e-02, -6.5349e-02, -1.2781e-02, -1.0318e-01,\n",
      "         -2.0891e-02, -1.7226e-01, -1.2774e-02, -1.8611e-02, -2.0249e-02,\n",
      "         -1.6760e-02,  7.5732e-03, -5.6147e-02, -1.6838e-02, -1.0475e-01,\n",
      "         -1.8159e-02, -6.6379e-04, -1.7816e-02, -1.8342e-02, -1.6192e-01,\n",
      "         -1.7023e-02, -5.1910e-02, -1.7825e-02, -2.1567e-02, -4.0431e-02,\n",
      "         -7.6901e-02, -5.7791e-02, -1.7724e-02, -1.4179e-02, -2.0355e-02,\n",
      "         -1.2705e-02, -1.3352e-02, -3.2609e-02,  2.9267e-02, -2.0486e-02,\n",
      "         -1.4043e-01, -2.7165e-02, -1.6749e-02,  3.3403e-02, -1.2642e-02,\n",
      "         -2.3153e-02,  3.9525e-03,  6.5503e-03, -1.3495e-02, -2.2905e-02,\n",
      "         -1.3964e-02, -1.0061e-02, -2.1039e-02, -9.5670e-02, -2.7423e-02,\n",
      "         -2.1615e-02, -5.4797e-02, -1.5398e-02, -3.6533e-02, -8.2265e-02,\n",
      "         -6.3102e-02, -2.3928e-02, -2.9334e-02, -9.3291e-02, -1.7954e-02,\n",
      "         -3.1102e-02, -1.7363e-02, -2.0346e-02, -2.1705e-02, -1.8357e-02,\n",
      "         -1.9847e-02, -4.4553e-02, -3.4771e-02, -2.2074e-02, -3.5480e-02,\n",
      "         -1.1344e-02, -2.4004e-02, -2.1129e-02, -1.9628e-02, -2.0508e-02,\n",
      "         -1.4668e-02, -2.2152e-02, -2.9211e-02, -2.6392e-02, -2.5351e-02,\n",
      "         -1.9850e-02,  8.4781e-03, -1.5128e-02, -1.2434e-02,  4.4926e-02,\n",
      "         -2.0449e-02, -1.4786e-02, -1.5156e-02, -1.8688e-02,  8.1105e-03,\n",
      "         -1.8344e-02, -9.7198e-03, -1.6399e-02, -2.5472e-02, -1.8104e-02,\n",
      "          2.8926e-02, -5.2897e-02, -1.8957e-02, -2.0191e-02, -1.5442e-02,\n",
      "         -1.1264e-01,  7.8628e-03, -1.7625e-02, -2.6766e-02, -1.3135e-02,\n",
      "          2.4292e-02, -9.9034e-03, -2.2321e-02, -2.1441e-02, -2.1661e-02,\n",
      "         -2.1026e-02, -2.5313e-02, -1.9051e-02, -1.7230e-02, -4.4673e-03,\n",
      "         -1.4263e-01,  3.4184e-02, -1.1089e-02, -1.1389e-02, -4.2689e-02,\n",
      "         -2.1324e-02,  8.1588e-04,  1.2943e-03, -5.2375e-02, -1.7953e-02,\n",
      "         -4.2650e-02, -1.2778e-02, -6.6434e-02, -1.0073e-01, -1.8705e-02,\n",
      "         -5.8055e-02, -2.3361e-02, -1.6994e-02, -8.9307e-03, -1.7182e-02,\n",
      "          1.1806e-03, -1.1633e-01, -1.3843e-02, -2.1599e-02, -1.7968e-02,\n",
      "         -1.9231e-02, -8.3045e-02, -1.4644e-02, -1.6366e-02, -1.0105e-01,\n",
      "         -2.0883e-02,  1.1988e-02, -1.5401e-02, -1.5196e-02, -1.3801e-02,\n",
      "         -1.9966e-02, -1.7851e-02, -2.4274e-02, -9.3300e-03, -1.2427e-02,\n",
      "         -2.4099e-02, -3.5442e-02, -1.2492e-01, -1.3712e-02, -1.7484e-02,\n",
      "         -1.1361e-01, -1.6419e-02, -1.7829e-02, -1.5447e-02, -1.6030e-02,\n",
      "          3.0642e-02, -1.5805e-02, -1.5818e-02, -4.2142e-02, -1.6358e-01,\n",
      "         -1.2205e-02,  3.7288e-02, -1.8252e-02, -1.4058e-02, -8.7980e-02,\n",
      "          1.4377e-02, -2.0518e-02,  1.0260e-02, -2.4473e-02,  5.2988e-03,\n",
      "         -2.2348e-02, -1.9569e-02, -2.6952e-02, -1.9860e-02, -1.5460e-02,\n",
      "         -1.9589e-02, -1.1629e-02, -1.5921e-02, -1.5865e-01, -1.4767e-02,\n",
      "         -1.1348e-02, -1.8642e-02, -1.1029e-02, -1.5544e-02, -2.1687e-02,\n",
      "          2.1349e-02, -2.2975e-02, -3.2831e-02, -1.0157e-02, -1.2270e-02,\n",
      "         -7.0669e-02, -2.2692e-02, -1.6750e-02, -1.5691e-02,  9.4728e-03,\n",
      "         -2.4074e-02, -2.8245e-02, -1.7509e-02, -5.0474e-02, -2.8883e-03,\n",
      "         -8.9414e-02, -2.2484e-02, -1.7801e-02, -1.3434e-02, -6.7200e-02,\n",
      "         -2.2333e-02, -2.6520e-03, -1.7262e-02, -2.7144e-02, -1.9086e-02,\n",
      "         -2.8299e-02, -2.1426e-02,  5.1540e-02, -1.6947e-02, -2.1370e-02,\n",
      "         -1.4823e-02, -4.1874e-02, -1.1928e-01, -2.1084e-02, -9.6849e-02,\n",
      "         -1.9587e-02, -1.2323e-02, -4.3554e-02, -4.7041e-02, -1.3874e-01,\n",
      "         -1.9187e-02,  3.4785e-02, -1.4251e-02, -2.4324e-02, -1.6396e-02,\n",
      "         -1.9600e-02, -1.6707e-02, -1.3408e-02, -1.1917e-01, -2.6066e-02,\n",
      "         -1.9074e-02, -6.8712e-03, -1.8715e-02,  1.4848e-02, -1.5296e-02,\n",
      "         -3.0961e-02, -2.9539e-02, -1.9205e-02, -8.3952e-02, -8.7190e-03,\n",
      "         -3.1039e-02, -1.8243e-02, -1.8218e-02, -1.9765e-02, -2.3213e-02,\n",
      "         -1.3705e-02, -2.6551e-02,  4.6335e-02, -1.5602e-02, -8.1057e-02,\n",
      "         -9.1322e-02, -1.3456e-02, -3.8291e-02, -2.0047e-02, -1.6432e-02,\n",
      "         -3.9160e-04, -2.3144e-02, -3.2221e-02, -2.2859e-02, -1.8027e-02,\n",
      "         -2.6999e-02, -1.7671e-02, -1.8065e-02, -1.5875e-02, -1.6465e-02,\n",
      "         -1.5115e-02, -1.9329e-02, -6.1875e-02, -3.1832e-02,  7.5761e-03,\n",
      "         -2.0552e-02, -1.8622e-02, -2.7820e-02, -1.9888e-02, -1.7281e-02,\n",
      "          4.7864e-02,  4.1890e-02, -1.5925e-02, -2.1062e-02,  4.0282e-03,\n",
      "         -1.4121e-02, -1.1623e-01, -1.8560e-02, -7.2963e-02,  6.0300e-03,\n",
      "          1.6246e-02, -1.7873e-02, -2.1686e-02, -1.7852e-02, -4.4206e-02,\n",
      "         -2.5556e-02, -1.7724e-02, -1.9139e-02, -1.5819e-02, -1.8102e-02,\n",
      "         -1.4516e-02,  8.7792e-03, -1.2582e-02, -2.6209e-02, -1.2461e-02,\n",
      "         -1.5031e-02, -3.9542e-02,  8.4141e-03, -1.6417e-02, -8.4528e-02,\n",
      "         -2.0810e-02, -9.4815e-02, -1.3846e-02, -1.2003e-01, -1.4850e-01,\n",
      "          1.5705e-02, -2.3324e-02, -4.2759e-02, -1.6034e-02, -2.5685e-02,\n",
      "         -2.0289e-02, -4.0324e-02, -1.8140e-02, -1.4444e-02, -1.9588e-02,\n",
      "         -1.7157e-02, -1.9985e-02, -2.3027e-02, -1.6298e-02, -4.1566e-02,\n",
      "         -4.8282e-02, -3.6243e-02, -1.5968e-02, -1.9029e-02, -1.9764e-02,\n",
      "         -4.5763e-02,  3.0707e-03, -1.3777e-02, -2.5722e-02, -2.5354e-02,\n",
      "         -1.1653e-02, -2.1833e-02, -1.9738e-02, -1.7258e-02, -2.1872e-02,\n",
      "         -9.5586e-02, -1.5109e-02, -2.4682e-02, -5.6114e-02, -2.9501e-02,\n",
      "          1.1827e-02, -1.3979e-02, -1.9813e-02, -1.8377e-02, -1.6129e-02,\n",
      "         -1.3467e-02, -2.1834e-02, -2.4717e-02, -9.0039e-02, -1.5864e-01,\n",
      "         -1.1320e-02, -2.8186e-02, -1.1207e-02, -1.3000e-02, -2.1760e-02,\n",
      "         -2.0066e-02, -1.6308e-02, -2.2762e-02, -1.2256e-01, -1.4098e-02,\n",
      "         -5.5037e-02, -8.4036e-02, -9.8556e-02, -1.2624e-02, -2.2094e-02,\n",
      "          6.7013e-02, -1.6465e-02, -1.3319e-02, -1.4352e-01, -1.7853e-02,\n",
      "          1.9187e-02, -1.5000e-02,  4.6913e-03, -2.6248e-02, -1.9235e-02,\n",
      "         -1.5809e-02, -1.4213e-02, -2.4966e-02,  2.2670e-02, -5.7775e-02,\n",
      "         -6.3693e-02, -1.5756e-01, -4.0272e-02, -1.8446e-02, -1.0864e-01,\n",
      "         -1.9775e-02, -8.7850e-02,  8.2853e-06, -1.9297e-02, -2.4087e-02,\n",
      "         -1.0036e-02, -2.3641e-01, -1.1042e-01, -1.6989e-02,  3.4619e-02,\n",
      "         -1.0434e-01, -1.6533e-02, -2.0547e-02, -1.7694e-02, -3.6587e-02,\n",
      "          5.7231e-03, -2.1320e-02, -1.5422e-02,  2.1310e-02, -2.4110e-02,\n",
      "         -1.6137e-02, -3.3052e-03, -1.3818e-02, -4.2290e-02, -2.3475e-02,\n",
      "         -1.3867e-02, -1.6535e-02, -1.8989e-02,  1.8183e-02, -2.1941e-02,\n",
      "         -2.9450e-02, -1.8583e-02, -2.0981e-02, -7.7220e-02, -2.2723e-02,\n",
      "         -5.4730e-02,  3.6908e-02, -1.5019e-02, -2.2912e-02, -7.7154e-02,\n",
      "         -2.2504e-02, -1.5708e-02,  6.5662e-03, -3.8390e-02, -2.9444e-02,\n",
      "         -1.8325e-02, -6.7862e-02, -1.3350e-02, -3.4115e-03, -1.1743e-02,\n",
      "         -1.4804e-02, -1.6121e-02, -2.4903e-02, -1.8480e-01, -2.1610e-02,\n",
      "         -1.4854e-02, -1.4943e-02]])\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from transformers import Wav2Vec2FeatureExtractor, WavLMForXVector\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/77064579/module-numpy-has-no-attribute-no-nep50-warning\n",
    "# def dummy_npwarn_decorator_factory():\n",
    "#   def npwarn_decorator(x):\n",
    "#     return x\n",
    "#   return npwarn_decorator\n",
    "# np._no_nep50_warning = getattr(np, '_no_nep50_warning', dummy_npwarn_decorator_factory)\n",
    "# https://stackoverflow.com/questions/51912284/how-to-downgrade-numpy\n",
    "\n",
    "print(np.__version__)\n",
    "\n",
    "# torchaudio.set_audio_backend(\"soundfile\")\n",
    "\n",
    "local_model_path = os.path.join(\"model\", \"models--microsoft--wavlm-base-plus-sv\", \"snapshots\", \"feb593a6c23c1cc3d9510425c29b0a14d2b07b1e\")\n",
    "\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(local_model_path)\n",
    "model = WavLMForXVector.from_pretrained(local_model_path)\n",
    "\n",
    "\n",
    "print(\"--->\", str(torchaudio.list_audio_backends()))\n",
    "\n",
    "# # Path to your .wav file\n",
    "wav_path = os.path.join(\"data\", \"cleansed\", \"brm_001\", \"male\", \"ajh001\", \"shortpassagea_CT.wav\")\n",
    "if not os.path.exists(wav_path):\n",
    "    raise FileNotFoundError(f\"WAV file not found at: {wav_path}\")\n",
    "\n",
    "\n",
    "# # # Load audio\n",
    "waveform, original_sr = torchaudio.load(wav_path)\n",
    "\n",
    "# Resample to 16kHz if needed\n",
    "target_sr = 16000\n",
    "if original_sr != target_sr:\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=original_sr, new_freq=target_sr)\n",
    "    waveform = resampler(waveform)\n",
    "\n",
    "# Convert to 1D numpy array\n",
    "audio_array = waveform.squeeze().numpy()\n",
    "\n",
    "# Extract features\n",
    "inputs = feature_extractor([audio_array], sampling_rate=target_sr, return_tensors=\"pt\", padding=True)\n",
    "with torch.no_grad():\n",
    "    embeddings = model(**inputs).embeddings\n",
    "    embeddings = torch.nn.functional.normalize(embeddings, dim=-1)\n",
    "\n",
    "print(embeddings.shape)  # Should be [1, 768]\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a5159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor, WavLMForXVector\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained('microsoft/wavlm-base-plus-sv')\n",
    "model = WavLMForXVector.from_pretrained('microsoft/wavlm-base-plus-sv')\n",
    "\n",
    "# audio files are decoded on the fly\n",
    "audio = [x[\"array\"] for x in dataset[:2][\"audio\"]]\n",
    "inputs = feature_extractor(audio, padding=True, return_tensors=\"pt\")\n",
    "embeddings = model(**inputs).embeddings\n",
    "embeddings = torch.nn.functional.normalize(embeddings, dim=-1).cpu()\n",
    "\n",
    "# the resulting embeddings can be used for cosine similarity-based retrieval\n",
    "cosine_sim = torch.nn.CosineSimilarity(dim=-1)\n",
    "similarity = cosine_sim(embeddings[0], embeddings[1])\n",
    "threshold = 0.86  # the optimal threshold is dataset-dependent\n",
    "if similarity < threshold:\n",
    "    print(\"Speakers are not the same!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c16fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2FeatureExtractor, AutoModel\n",
    "\n",
    "# Load model and feature extractor\n",
    "model_name = \"microsoft/wavlm-base-plus-sv\"\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()  # Inference mode\n",
    "\n",
    "# Load a .wav file\n",
    "file_path = \"data/cleansed/BRM/male/spk01/shortpassage_001.wav\"  # <- Change this as needed\n",
    "waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "# Resample to 16kHz if needed\n",
    "if sample_rate != 16000:\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "    waveform = resampler(waveform)\n",
    "\n",
    "# Convert stereo to mono if needed\n",
    "if waveform.shape[0] > 1:\n",
    "    waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "# Extract input values\n",
    "inputs = feature_extractor(waveform.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\")\n",
    "\n",
    "# Forward pass through model to get embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_state = outputs.last_hidden_state  # (batch_size, time_steps, feature_dim)\n",
    "\n",
    "# Aggregate embeddings (e.g., mean pooling across time)\n",
    "embedding = last_hidden_state.mean(dim=1).squeeze()  # shape: (feature_dim,)\n",
    "\n",
    "print(f\"Extracted embedding shape: {embedding.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
