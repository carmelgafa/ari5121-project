{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "820656f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6caf173c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Folder structure\n",
    "\n",
    "The following folder structure will be used in this project\n",
    "\n",
    "VoiceSimilarityAnalysis-code\n",
    "├── data\n",
    "│   ├── download              # Contains downloaded zip files (e.g. ABI-1_Corpus.zip)\n",
    "│   ├── raw/                   # Unzipped original dataset (14 accent folders)\n",
    "│   └── cleansed/              # Contains only the filtered \"shortpassage\" .wav files\n",
    "│\n",
    "├── reports/                  # Drafts and final version of the report\n",
    "│\n",
    "├── results/                  # Output files: embeddings, similarity scores, matrices, plots\n",
    "│\n",
    "├── appendix/                 # Generative AI chat logs for submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "769ac352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports go here\n",
    "import os\n",
    "import zipfile\n",
    "import gdown\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022a72ea",
   "metadata": {},
   "source": [
    "## Step 1 - download the dataset\n",
    "\n",
    "In an effort to totally automate the process, the dataset will be downloaded in a raw-data folder using the following code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7bbad0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=18FWBn4B6gQifOtf1C9JCQv4Lrs8C1uvu\n",
      "From (redirected): https://drive.google.com/uc?id=18FWBn4B6gQifOtf1C9JCQv4Lrs8C1uvu&confirm=t&uuid=e299ebfa-0e41-4c1f-8280-7b9ba24e9779\n",
      "To: /Users/carmelgafa/Documents/my-work/ari5121-project/VoiceSimilarityAnalysis-code/data/download/ABI-1_Corpus/ABI-1_Corpus.zip\n",
      "100%|██████████| 2.82G/2.82G [04:27<00:00, 10.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data downloaded...\n"
     ]
    }
   ],
   "source": [
    "# 7 minutes on Costa wifi -- execute and have a coffee\n",
    "\n",
    "# gdrive id\n",
    "file_id = \"18FWBn4B6gQifOtf1C9JCQv4Lrs8C1uvu\"\n",
    "\n",
    "# download the file\n",
    "download_folder = os.path.join(\"data\", \"download\", \"ABI-1_Corpus\")\n",
    "if not os.path.exists(download_folder):\n",
    "    os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "download_path = os.path.join(download_folder, \"ABI-1_Corpus.zip\")\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", download_path, quiet=False)\n",
    "\n",
    "# open the zip\n",
    "raw_folder = os.path.join(\"data\", \"raw\", \"ABI-1_Corpus\")\n",
    "if not os.path.exists(raw_folder):\n",
    "    os.makedirs(raw_folder, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(raw_folder)\n",
    "\n",
    "print(\"Raw data downloaded...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7081537",
   "metadata": {},
   "source": [
    "## Step 2 - Cleanse the dataset\n",
    "\n",
    "We will only keep the \"shortpassage*.wav\" files for each accent in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235d557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleansing completed...\n"
     ]
    }
   ],
   "source": [
    "raw_data_folder = \"data/raw/ABI-1_Corpus/ABI-1 Corpus/accents\"\n",
    "cleansed_dir = \"data/cleansed\"\n",
    "\n",
    "\n",
    "# list accent folders removing the annoying folders\n",
    "accents = [accent_folder for accent_folder in os.listdir(raw_data_folder) if not accent_folder.startswith(\".\")]\n",
    "# go through all accents\n",
    "for accent in accents:\n",
    "    accent_path = os.path.join(raw_data_folder, accent)\n",
    "    # list all genders in each accent\n",
    "    genders = [gender_folder for gender_folder in os.listdir(accent_path) if not gender_folder.startswith(\".\")]\n",
    "    # go through all genders in each accent\n",
    "    for gender in genders:  \n",
    "        gender_folder = os.path.join(accent_path, gender)\n",
    "        # go througgh each speaker in each gender\n",
    "        # lsit all speakers\n",
    "        speakers = [speaker for speaker in os.listdir(gender_folder) if not speaker.startswith(\".\")]\n",
    "        for speaker in speakers:\n",
    "            speaker_path = os.path.join(gender_folder, speaker)\n",
    "\n",
    "            # store resulting  data in cleaned/accent/gender/speaker\n",
    "            dest_path = os.path.join(cleansed_dir, accent, gender, speaker)\n",
    "            os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "            # copy only filenames that  are shortpassage*.wav\n",
    "            # go throough all files        \n",
    "            for filename in os.listdir(speaker_path):\n",
    "                if re.fullmatch(r\"shortpassage.*\\.wav\", filename):\n",
    "\n",
    "                    src_file = os.path.join(speaker_path, filename)\n",
    "                    dst_file = os.path.join(dest_path, filename)\n",
    "                    shutil.copy2(src_file, dst_file)\n",
    "\n",
    "print(\"Cleansing completed...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
